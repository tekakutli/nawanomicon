:PROPERTIES:
:ID:       8300ca3c-deff-4147-9c31-b7c54e5780d3
:END:
#+title: segmentation
#+filetags: :nawanomicon:
- parent: [[id:39d30d24-c374-4d0c-8037-b03ecbf983fa][computer_vision]]
- [[https://github.com/vijishmadhavan/ArtLine][ArtLine]]: gan to get artline from image, maybe instead of canny for controlnet?
- [[https://arxiv.org/abs/2304.03284][SegGPT]]: Segmenting Everything In Context
  - [[https://github.com/baaivision/Painter][Painter]] & SegGPT Series: Vision Foundation Models from BAAI (radiography components, top of box)
- [[https://twitter.com/_akhaliq/status/1667053581944455174][Background]] Prompting for Improved Object Depth
  - learned background prompt, thus focuses in the object
- object detection and segmentator: https://github.com/facebookresearch/CutLER
* SAM
:PROPERTIES:
:ID:       1eb158d5-47a5-42a4-8692-86c42376d25a
:END:
- [[https://twitter.com/_akhaliq/status/1645115958594351106][SAM + DINO]], [[https://github.com/mattyamonaca/PBRemTools][segment]] anything, image region editing
- [[https://huggingface.co/papers/2306.01567][high quality sam]]
  - [[https://twitter.com/_akhaliq/status/1666273462766170113][Recognize]] Anything: A Strong Image Tagging Model
- https://arxiv.org/abs/2304.06718 [[https://github.com/UX-Decoder/Segment-Everything-Everywhere-All-At-Once][Segment-Everything-Everywhere-All-At-Once]]
- [[https://github.com/geekyutao/Inpaint-Anything][inpainting]]
- [[https://arxiv.org/abs/2306.12156][Fast Segment]] Anything, [[https://github.com/casia-iva-lab/fastsam][40ms per]] image
- segment videos https://github.com/gaomingqi/Track-Anything
- [[https://twitter.com/_akhaliq/status/1678599147455119363][Semantic-SAM]]: Segment and Recognize Anything at Any Granularity
  - generate masks at multiple levels
** USE CASES
- see relationships between them https://github.com/Luodian/RelateAnything
- [[https://twitter.com/_akhaliq/status/1667027179308195843][Matting]] Anything Model (MAM): green screen-ed
- [[https://twitter.com/_akhaliq/status/1676092343148064770][Segment]] Anything Meets Point Tracking, follow pixels, [[id:88e29751-d7d6-41e4-8375-3c7ac24cb77b][OPTICAL FLOW]]
* 3D SEGMENATION
  - [[https://github.com/Jumpat/SegmentAnythingin3D][Segment]] Anything in 3D with NeRFs (SA3D)
    - [[https://twitter.com/_akhaliq/status/1665926124487036929][SAM3D]]: Zero-Shot 3D Object Detection via Segment Anything Model
  - [[https://twitter.com/liuziwei7/status/1651461200956514306][SAD is]] able to perform 3D segmentation (segment out any 3D object) with RGBD inputs
* DIFFUSION SEGMENATION
- parent: [[id:c7fe7e79-73d3-4cc7-a673-2c2e259ab5b5][stable_diffusion]]
- [[https://weichen582.github.io/diffmae.html][Diffusion Models]] [[https://arxiv.org/abs/2304.03283][as Masked]] Autoencoders
- [[https://jerryxu.net/ODISE/][ODISE]]: Open-Vocabulary [[https://github.com/NVlabs/ODISE][Panoptic]] Segmentation with Text-to-Image Diffusion Models.
- [[https://twitter.com/_akhaliq/status/1669588008117338113][Diffusion Models]] for Zero-Shot Open-Vocabulary Segmentation (considers the contextual background)
